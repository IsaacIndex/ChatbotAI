{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig, pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('./Source Docs/', glob=\"./*.pdf\", loader_cls=PyPDFLoader)\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Page 1 of 24https://www.destinypedia.com/Lore:Ghost_Stories\\nSign up Login\\nNavigationGames\\nOther media\\nGameplay\\nThe universe\\nLore database\\nCommunity InfoDestinypedia\\nWiki help\\nRelated sites\\nBungie.netRecent changes Random pageSpecial pages What links hereDid you know?...that the Red Legion were feared across the galaxy as destroyers of worlds?...that the Dreadnaught was partially constructed out of a part of Akka's corpse?...that Zhalo Supercell was originally named after the hammer of the Finnish thunder god Ukko?...that while Mercury was shown to only be partially converted into a machine world during theDark Age in Season of Dawn, it was previously stated in Destiny that it had been converted in amatter of days?...that Ghost was originally voiced by Peter Dinklage, but his lines were re-recorded by Nolan Northand completely replaced with Destiny patch 2.0.0?Lore Discussion View source HistoryLore:Ghost StoriesFrom Destinypedia, the Destiny wiki\\nDiscord\\n chat\\nSearch Destinypedia\", metadata={'source': 'Source Docs/Lore:Ghost Stories - Destinypedia, the Destiny wiki.pdf', 'page': 0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)7f436/.gitattributes: 100%|██████████| 1.48k/1.48k [00:00<00:00, 190kB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 270/270 [00:00<00:00, 173kB/s]\n",
      "Downloading (…)/2_Dense/config.json: 100%|██████████| 116/116 [00:00<00:00, 181kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 3.15M/3.15M [00:01<00:00, 2.39MB/s]\n",
      "Downloading (…)0daf57f436/README.md: 100%|██████████| 66.3k/66.3k [00:00<00:00, 27.6MB/s]\n",
      "Downloading (…)af57f436/config.json: 100%|██████████| 1.52k/1.52k [00:00<00:00, 3.16MB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 122/122 [00:00<00:00, 207kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 4.96G/4.96G [04:02<00:00, 20.5MB/s]\n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 20.7kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 2.20k/2.20k [00:00<00:00, 780kB/s]\n",
      "Downloading spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 848kB/s]\n",
      "Downloading (…)7f436/tokenizer.json: 100%|██████████| 2.42M/2.42M [00:01<00:00, 2.25MB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 2.40k/2.40k [00:00<00:00, 939kB/s]\n",
      "Downloading (…)f57f436/modules.json: 100%|██████████| 461/461 [00:00<00:00, 186kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "# use huggingface instructor embeddings\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\", model_kwargs={\"device\": \"cpu\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and store embeddings in Chroma\n",
    "persist_directory = 'db'\n",
    "vectordb = Chroma.from_documents(documents=texts, \n",
    "                                 embedding=instructor_embeddings,\n",
    "                                 persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='25/5/2023, 5:29 PMLore:The Man They Call Cayde - Destinypedia, the Destiny wiki\\nPage 1 of 16https://www.destinypedia.com/Lore:The_Man_They_Call_Cayde\\nSign up Login\\nNavigationGames\\nOther media\\nGameplay\\nThe universe\\nLore database\\nCommunity InfoDestinypedia\\nWiki help\\nRelated sites\\nBungie.netRecent changes Random pageSpecial pages What links hereDid you know?...that the Ahamkara are shapeshifters?...that Oryx is responsible for the Taken invasion of the Dreaming City, and the taking of Riven?...that the Sword Heavy Weapon class was ﬁrst introduced in The Taken King?...that while Fallen Dregs can be seen piloting Pikes, no Cabal was ever seen piloting an Interceptorin Destiny until Destiny 2?...that the Hunter Ana Bray was thought to be dead until she reappeared on Mars to investigate herpast?Lore Discussion View source HistoryLore:The Man They Call CaydeFrom Destinypedia, the Destiny wiki\\nDiscord\\n chat', metadata={'source': 'Source Docs/Lore:The Man They Call Cayde - Destinypedia, the Destiny wiki.pdf', 'page': 0}),\n",
       " Document(page_content='25/5/2023, 5:29 PMLore:The Man They Call Cayde - Destinypedia, the Destiny wiki', metadata={'source': 'Source Docs/Lore:The Man They Call Cayde - Destinypedia, the Destiny wiki.pdf', 'page': 2}),\n",
       " Document(page_content='25/5/2023, 5:29 PMLore:The Man They Call Cayde - Destinypedia, the Destiny wiki', metadata={'source': 'Source Docs/Lore:The Man They Call Cayde - Destinypedia, the Destiny wiki.pdf', 'page': 4}),\n",
       " Document(page_content='25/5/2023, 5:29 PMLore:The Man They Call Cayde - Destinypedia, the Destiny wiki', metadata={'source': 'Source Docs/Lore:The Man They Call Cayde - Destinypedia, the Destiny wiki.pdf', 'page': 8})]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectordb.as_retriever()\n",
    "docs = retriever.get_relevant_documents(\"Who is Clovis Bray?\")\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 555/555 [00:00<00:00, 91.7kB/s]\n",
      "Downloading (…)model.bin.index.json: 100%|██████████| 26.8k/26.8k [00:00<00:00, 7.39MB/s]\n",
      "Downloading (…)l-00001-of-00002.bin: 100%|██████████| 9.98G/9.98G [08:01<00:00, 20.7MB/s]\n",
      "Downloading (…)l-00002-of-00002.bin: 100%|██████████| 3.50G/3.50G [02:54<00:00, 20.0MB/s]\n",
      "Downloading shards: 100%|██████████| 2/2 [10:58<00:00, 329.43s/it]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'init_empty_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m tokenizer \u001b[39m=\u001b[39m LlamaTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mTheBloke/wizardLM-7B-HF\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m model \u001b[39m=\u001b[39m LlamaForCausalLM\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mTheBloke/wizardLM-7B-HF\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m                                               load_in_8bit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      5\u001b[0m                                               device_map\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mauto\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m                                               torch_dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat16,\n\u001b[1;32m      7\u001b[0m                                               low_cpu_mem_usage\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m                                               )\n",
      "File \u001b[0;32m~/Documents/Programming/AI/ChatbotAI-D2/.venv/lib/python3.9/site-packages/transformers/modeling_utils.py:2608\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2606\u001b[0m     init_contexts \u001b[39m=\u001b[39m [deepspeed\u001b[39m.\u001b[39mzero\u001b[39m.\u001b[39mInit(config_dict_or_path\u001b[39m=\u001b[39mdeepspeed_config())] \u001b[39m+\u001b[39m init_contexts\n\u001b[1;32m   2607\u001b[0m \u001b[39melif\u001b[39;00m load_in_8bit \u001b[39mor\u001b[39;00m low_cpu_mem_usage:\n\u001b[0;32m-> 2608\u001b[0m     init_contexts\u001b[39m.\u001b[39mappend(init_empty_weights())\n\u001b[1;32m   2610\u001b[0m \u001b[39mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[1;32m   2611\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(config, \u001b[39m*\u001b[39mmodel_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'init_empty_weights' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(\"TheBloke/wizardLM-7B-HF\")\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\"TheBloke/wizardLM-7B-HF\",\n",
    "                                              load_in_8bit=True,\n",
    "                                              device_map='auto',\n",
    "                                              torch_dtype=torch.float16,\n",
    "                                              low_cpu_mem_usage=True\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=1024,\n",
    "    temperature=0,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.15\n",
    ")\n",
    "\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm=local_llm, \n",
    "                                  chain_type=\"stuff\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def wrap_text_preserve_newlines(text, width=110):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    print(wrap_text_preserve_newlines(llm_response['result']))\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full example\n",
    "query = \"Who is Clovis?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
